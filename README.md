# Awful AI
**Awful AI** is a curated list to track *current* scary usages of AI - hoping to raise awareness to its misuses in society



Artificial intelligence in its current state is [unfair](https://github.com/rockita/criticalML) and easily [susceptible to attacks](http://www.cleverhans.io/security/privacy/ml/2016/12/15/breaking-things-is-easy.html). Nevertheless, more and more concerning uses of AI technology are appearing in the wild. This list aims to track *all of them*. We hope that *Awful AI* can be a platform to spur discussion for the development of possible contestational technology (to fight back!).

---

## Discrimination

[HireVue](https://www.hirevue.com/) - App that scans your face and tells companies whether you’re worth hiring [[summary](https://www.theladders.com/career-advice/ai-screen-candidates-hirevue)]

[AI-based Gaydar](https://osf.io/zn79k/) - Artificial intelligence can accurately guess whether people are gay or straight based on photos of their faces, according to new research that suggests machines can have significantly better “gaydar” than humans [[summary](https://www.theguardian.com/technology/2017/sep/07/new-artificial-intelligence-can-tell-whether-youre-gay-or-straight-from-a-photograph)]

[Racist Chat Bots]() - Microsoft chatbot called Tay spent a day learning from Twitter and began spouting antisemitic messages [[summary](https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter)]

[Racist Auto Tag]() - a Google image recognition program labelled the faces of several black people as gorillas [[summary](https://www.theguardian.com/technology/2015/jul/01/google-sorry-racist-auto-tag-photo-app)]

[PredPol](http://www.predpol.com/) - PredPol, a program for police departments that predicts hotspots where future crime might occur, could potentially get stuck in a feedback loop of over-policing majority black and brown neighbourhoods [[summary](https://www.themarshallproject.org/2016/02/03/policing-the-future?ref=hp-2-111#.UyhBLnmlj)]

[COMPAS](http://www.equivant.com/challenges/supervision-and-compliance-monitoring) - is a risk assessment algorithm used in legal courts by the state of Wisconsin to predict the risk of recidivism. Its manufacturer refuses to disclose the proprietary algorithm and only the final risk assessment score is known. The algorithm is biased against blacks (even worse than humans) [[summary](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)][[NYT opinion](https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html)]

## Influencing, desinformation and fakes

[Cambridge Analytica](https://cambridgeanalytica.org/) - Cambridge Analytica uses Facebook data to change audience behavior for political and commercial causes [[Guardian article](https://www.theguardian.com/news/2018/mar/26/the-cambridge-analytica-files-the-story-so-far)]

[Deep Fakes](https://www.deepfakes.club/) - Deep Fakes is an artificial intelligence-based human image synthesis technique. It is used to combine and superimpose existing images and videos onto source images or videos. Deepfakes may be used to create fake celebrity pornographic videos or revenge porn. [[AI assisted fake porn](https://www.vice.com/en_us/article/bj5and/ai-assisted-fake-porn-is-here-and-were-all-fucked)]

[Fake News Bots]() - Automated accounts are being programmed to spread fake news. In recent times, fake news has been used to manipulate stock markets, make people choose dangerous health-care options, and manipulate elections, including last year’s presidential election in the U.S. [[summary](https://www.wired.com/story/internet-freedom-2017/)][[role of bots](https://www.technologyreview.com/s/608561/first-evidence-that-social-bots-play-a-major-role-in-spreading-fake-news/)]

[Attention Engineering]() - From Facebook notifications to Snapstreaks to YouTube autoplays, they're all competing for one thing: your attention. Companies prey on our psychology for their own profit [[TED Talk](https://www.ted.com/talks/tristan_harris_the_manipulative_tricks_tech_companies_use_to_capture_your_attention)]

## Social credit systems

[Social Credit System](https://en.wikipedia.org/wiki/Social_Credit_System) - Using a secret algorithm, Sesame credit constantly scores people from 350 to 950, and its ratings are based on factors including considerations of “interpersonal relationships” and consumer habits - [[summary](https://www.theguardian.com/commentisfree/2018/mar/05/algorithms-rate-credit-scores-finances-data)][[travel ban](https://www.telegraph.co.uk/news/2018/03/24/chinas-social-credit-system-bans-millions-travelling/)]

[Vitality](https://www.vitality.co.uk/media/vitality-extends-active-rewards-with-apple-watch-series-3/) - Health insurance company that offer deals based on access to data from fitness trackers [[summary](https://www.theguardian.com/commentisfree/2018/mar/05/algorithms-rate-credit-scores-finances-data)]

## Surveillance

[SenseTime](https://www.sensetime.com/intelligentVideo/84) & [Megvii](https://megvii.com/)- Based on Face Recognition technology powered by deep learning algorithm, SenseFace and Megvii provides integrated solutions of intelligent video analysis, which functions in target surveillance, trajectory analysis, population management [[summary](https://www.reuters.com/article/us-china-facialrecognition-analysis/backing-big-brother-chinese-facial-recognition-firms-appeal-to-funds-idUSKBN1DD00A)][[forbes](https://www.forbes.com/sites/shuchingjeanchen/2018/03/07/the-faces-behind-chinas-omniscient-video-surveillance-technology/#54401e4f4afc)]

[Uber God View](https://www.forbes.com/sites/kashmirhill/2014/10/03/god-view-uber-allegedly-stalked-users-for-party-goers-viewing-pleasure/#70a9f7a43141) - Uber's "God View" let Uber employees see all of the Ubers in a city and the silhouettes of waiting Uber users who have flagged cars - including names [[rides of glory](https://rideofglory.wordpress.com/)]

[Palantir](http://www.palantir.com/) - A billion-dollar startup that focuses on predictive policies, intelligence and ai-powered military defense systems [[summary](https://www.theverge.com/2018/3/10/17104878/palantir-us-army-contract-peter-thiel-data-intelligence-distributed-common-ground-system-tech)]

---

## Contestational tech projects

> These open source projects try to spur discourse, offer protection or awareness to awful AI

[Data Selfie](https://dataselfie.it/#/) - Data Selfie is a browser extension that tracks you while you are on Facebook to show you your own data traces and reveal what machine learning algorithms could predict about your personality based on that data [[code](https://github.com/d4t4x/data-selfie)]

[AdNauseam](https://adnauseam.io/) - AdNauseam is a lightweight browser extension to fight back against tracking by advertising networks. It works like an ad-blocker (it is built atop uBlock-Origin) to silently simulate clicks on each blocked ad, confusing trackers as to one's real interests [[code](https://github.com/dhowe/AdNauseam)]

## Licenses
License

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [David Dao](http://daviddao.org/) has waived all copyright and related or neighboring rights to this work.
